{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKzqHxxc3IfNpblvMcIAnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khawla-1/ResponseAssessment/blob/master/AssessmentResponse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In this document I'll give a response for the Technical Assessment"
      ],
      "metadata": {
        "id": "riuTyLr2TNkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**: Implement Partial Cross Entropy Loss\n",
        "Partial Cross Entropy (PCE)"
      ],
      "metadata": {
        "id": "f0RKMrFeTdwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Q1jolCuS93B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PartialCrossEntropyLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PartialCrossEntropyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, predictions, labels, mask):\n",
        "\n",
        "        # Flatten tensors for mask application\n",
        "        predictions = predictions.permute(0, 2, 3, 1).reshape(-1, predictions.size(1))  # [N, C]\n",
        "        labels = labels.view(-1)  # [N]\n",
        "        mask = mask.view(-1)  # [N]\n",
        "\n",
        "        # Mask predictions and labels\n",
        "        predictions = predictions[mask == 1]\n",
        "        labels = labels[mask == 1]\n",
        "\n",
        "        # Standard Cross Entropy Loss\n",
        "        loss = nn.CrossEntropyLoss()(predictions, labels)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task 2**: Task 2: Find Remote Sensing Data, Simulate Point Labels, and Integrate Loss"
      ],
      "metadata": {
        "id": "BXjP60eGT0R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Objective: Test the PartialCrossEntropyLoss with remote sensing data and simulate sparse annotations.\n",
        "\n",
        "Implementation:\n",
        "\n",
        "1 - Data Loading: start by remote sensing dataset like EuroSAT or DeepGlobe. then simulate point labels with a random sampling strategy.\n",
        "\n",
        "2- Integrate Partial Cross Entropy Loss: Implement it into a semantic segmentation framework (e.g., U-Net).\n"
      ],
      "metadata": {
        "id": "9acO6NiqiXmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import VOCSegmentation\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "# Load remote sensing dataset\n",
        "def load_remote_sensing_data():\n",
        "    transform = T.Compose([T.Resize((256, 256)), T.ToTensor()])\n",
        "    dataset = VOCSegmentation(root='./data', year='2012', image_set='train', download=True, transform=transform)\n",
        "    return DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Simulate sparse point labels\n",
        "def simulate_point_labels(segmentation_labels, num_points=50):\n",
        "\n",
        "    batch_size, height, width = segmentation_labels.shape\n",
        "    sparse_labels = torch.zeros_like(segmentation_labels)\n",
        "    mask = torch.zeros_like(segmentation_labels)\n",
        "\n",
        "    for batch_idx in range(batch_size):\n",
        "        for _ in range(num_points):\n",
        "            x, y = np.random.randint(0, height), np.random.randint(0, width)\n",
        "            sparse_labels[batch_idx, x, y] = segmentation_labels[batch_idx, x, y]\n",
        "            mask[batch_idx, x, y] = 1\n",
        "    return sparse_labels, mask\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AbOAhnl7VuvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bjTxNJnTj0Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 3** Design Experiments"
      ],
      "metadata": {
        "id": "KfaRC3Zci_9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Purpose**:\n",
        "\n",
        "* Assess the impact of labeled point density (10, 50, 100 points per image).\n",
        "* Test semi-supervised learning techniques like self-training or consistency regularization.\n",
        "\n",
        "**Hypothesis**:\n",
        "* More labeled points improve segmentation performance.\n",
        "* Semi-supervised approaches enhance performance by leveraging unlabeled regions.\n",
        "\n",
        "**Experimental Process**:\n",
        "\n",
        "* Train U-Net using PartialCrossEntropyLoss with different point densities.\n",
        "* Implement pseudo-labeling for unlabeled regions."
      ],
      "metadata": {
        "id": "3hdglzt1jTnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define U-Net or any segmentation model\n",
        "class UNet(nn.Module):\n",
        "    # Define model architecture\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        # ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ...\n",
        "        return x\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=10, point_density=50):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        for images, labels in tqdm(dataloader):\n",
        "            # Simulate sparse annotations\n",
        "            sparse_labels, mask = simulate_point_labels(labels, num_points=point_density)\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(images)\n",
        "\n",
        "            # Loss calculation\n",
        "            loss = criterion(predictions, sparse_labels, mask)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader)}\")\n",
        "\n",
        "# Experiment\n",
        "def experiment():\n",
        "    dataloader = load_remote_sensing_data()\n",
        "    model = UNet()\n",
        "    criterion = PartialCrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Vary point density and observe performance\n",
        "    for point_density in [10, 50, 100]:\n",
        "        print(f\"\\nTraining with {point_density} labeled points per image\")\n",
        "        train_model(model, dataloader, criterion, optimizer, num_epochs=5, point_density=point_density)\n"
      ],
      "metadata": {
        "id": "nS-elq9ijt5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import VOCSegmentation\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Load remote sensing dataset with proper transformations\n",
        "def load_remote_sensing_data():\n",
        "    transform = T.Compose([\n",
        "        T.Resize((256, 256)),  # Resize images and labels\n",
        "        T.ToTensor(),          # Convert images to tensors\n",
        "    ])\n",
        "\n",
        "    target_transform = T.Compose([\n",
        "        T.Resize((256, 256)),  # Resize segmentation masks\n",
        "        T.PILToTensor(),       # Convert masks to tensors\n",
        "    ])\n",
        "\n",
        "    dataset = VOCSegmentation(\n",
        "        root='./data',\n",
        "        year='2012',\n",
        "        image_set='train',\n",
        "        download=True,\n",
        "        transform=transform,\n",
        "        target_transform=target_transform\n",
        "    )\n",
        "    return DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Example usage\n",
        "dataloader = load_remote_sensing_data()\n",
        "images, labels = next(iter(dataloader))\n",
        "print(images.shape, labels.shape)  # Validate tensor shapes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jglG0fVmkQts",
        "outputId": "0805a87e-34e6-40db-b2a6-c32683aee70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
            "torch.Size([4, 3, 256, 256]) torch.Size([4, 1, 256, 256])\n"
          ]
        }
      ]
    }
  ]
}